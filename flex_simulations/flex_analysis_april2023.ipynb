{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code goes through the flexibility simulation outputs and looks for how many of them are correct\n",
    "# It then makes fig 2\n",
    "# As stated below but also up here we need to put the outputs (currently in the tar.gz file into their own directories)\n",
    "\n",
    "# Note because of the relatively small numbers of simulations involved in this, we ran everything 10* to see variability across the 10 runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from Bio import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = SeqIO.parse(\"db_formatted.fasta\", \"fasta\")\n",
    "db = {k.id:k.seq for k in db}\n",
    "# This DB just contains unique sequences and names have been renamed to make things run easily with all programs\n",
    "\n",
    "linkfile = \"db_link.csv\"\n",
    "link = pd.read_csv(linkfile, index_col=0, header=None)\n",
    "rlink = pd.read_csv(linkfile, index_col=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pd.read_csv(\"flex_correct.csv\")\n",
    "correct_dict = {}\n",
    "for i in range(len(correct)):\n",
    "    correct_dict[correct.iloc[i].sequence] = correct.iloc[i].correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_formatted.fasta   flex_correct.csv     flex_outputs.tar.gz\r\n",
      "db_link.csv          flex_example.ipynb\r\n",
      "flex_analysis.ipynb  flex_fastas.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "# Note all the outputs are in the flex_outputs.tar.gz tarball. The subdirectories, (flex{n}_output) need to be in the current directory for this code to run.\n",
    "# Extract and place folders in this directory.\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now writing cleaner code to go to github\n",
    "\n",
    "def conv_string(b):\n",
    "    if b == True:\n",
    "        return(\"1\")\n",
    "    else:\n",
    "        return(\"0\")\n",
    "\n",
    "# Defining a simulation class\n",
    "# For any given flexibility simulation it is defined by the sequence inserted and which run it was in\n",
    "\n",
    "class simulation:\n",
    "    \n",
    "    def __init__(self, sequence, run):\n",
    "        self.sequence = sequence\n",
    "        self.sim_fl = \"\" # I need to pull these back off analysis 1\n",
    "        self.run = run\n",
    "        self.correct = correct_dict[self.sequence]\n",
    "        self.origname = link.loc[self.correct][1]\n",
    "        self.origname_seq = link.loc[self.correct][2]\n",
    "        \n",
    "        #Abricate\n",
    "        self.abricate_fl = \"flex{0}_output/abricate_summary/{1}_assem.tab\" .format(self.run, self.sequence)\n",
    "        self.abricate_result = pd.read_csv(self.abricate_fl, delimiter = \"\\t\")\n",
    "        self.abricate_genes = list(self.abricate_result[\"GENE\"])\n",
    "        \n",
    "        #ARIBA\n",
    "        self.ariba_fl = \"flex{0}_output/ariba_summary/{1}.expandedreport.tsv\" .format(self.run, self.sequence)\n",
    "        self.ariba_result = pd.read_csv(self.ariba_fl, delimiter = \"\\t\")\n",
    "        self.ariba_genes = list(self.ariba_result['ref_name'])\n",
    "        \n",
    "        #KmerResistance\n",
    "        self.kmerres_fl = \"flex{0}_output/kmerres_summary/{1}.KmerRes\" .format(self.run, self.sequence)\n",
    "        self.kmerres_result = pd.read_csv(self.kmerres_fl, delimiter = \"\\t\")\n",
    "        # Note here I have had to apply the cutoff manually as KmerResistance doesn't appear to manually do this\n",
    "        # Its files suggest its \"template id cutoff\" should be 70.0.\n",
    "        self.kmerres_result = self.kmerres_result.loc[self.kmerres_result.template_id > 70.0]\n",
    "        self.kmerres_genes = sorted(list(set([k for k in list(self.kmerres_result['#Template']) if \"resfindernewid\" in str(k)])))\n",
    "        \n",
    "        #SRST2\n",
    "        # Note an important point to begin is that if SRST2 doesn't find anything, it doesn't create a results file at its final reporting stage.\n",
    "        # Therefore I have included a tag to pull these ones out if you want to look at the original file\n",
    "        self.srst2_fl = \"flex{0}_output/srst2_summary/{1}_SRST.out__fullgenes__seqs_clustered__results.txt\" .format(self.run, self.sequence)\n",
    "        if os.path.isfile(self.srst2_fl):\n",
    "            self.srst2_result = pd.read_csv(self.srst2_fl, delimiter = \"\\t\")\n",
    "            self.srst2_genes = sorted(list(set(list(self.srst2_result.allele))))\n",
    "        else:\n",
    "            self.srst2_result = \"Empty\"\n",
    "            self.srst2_genes = []\n",
    "        \n",
    "        # Output investigation\n",
    "        self.matching = [self.abricate_genes == [self.correct] , \n",
    "                                   self.ariba_genes == [self.correct],\n",
    "                                  self.kmerres_genes == [self.correct], \n",
    "                                  self.srst2_genes == [self.correct]]\n",
    "        self.matching_string = \":\".join([conv_string(j) for j in self.matching])\n",
    "        self.any_error = False in self.matching\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File flex1_output/abricate_summary/flex_0_assem.tab does not exist: 'flex1_output/abricate_summary/flex_0_assem.tab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-84805b1080f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorrect_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msimulation_outcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-20f18259dddf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequence, run)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#Abricate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabricate_fl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"flex{0}_output/abricate_summary/{1}_assem.tab\"\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabricate_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabricate_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabricate_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabricate_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GENE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/timdavies/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/timdavies/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/timdavies/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/timdavies/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/timdavies/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File flex1_output/abricate_summary/flex_0_assem.tab does not exist: 'flex1_output/abricate_summary/flex_0_assem.tab'"
     ]
    }
   ],
   "source": [
    "sims = {} # This stores all out the simulation objects\n",
    "simulation_outcome = {} # This is just a straightforwad \n",
    "\n",
    "\n",
    "\n",
    "# So this reads in all the results and goes through things.\n",
    "# Note we use range 1,11 as there were 10 repeats\n",
    "\n",
    "for r in range(1, 11):\n",
    "    sims[r] = {}\n",
    "    for n in tnrange(len(list(correct_dict.keys()))):\n",
    "        k = list(correct_dict.keys())[n]\n",
    "        x = simulation(k, r)\n",
    "        sims[r][k] = x\n",
    "        simulation_outcome.setdefault(k, []).append(x.any_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n"
     ]
    }
   ],
   "source": [
    "# You can then use this dictionary to query what you want\n",
    "errors_list = []\n",
    "\n",
    "for k in simulation_outcome:\n",
    "    if True in simulation_outcome[k].any_error:\n",
    "        errors_list.append(k)\n",
    "\n",
    "print(len(errors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we use it to make our fig as seen in the paper\n",
    "\n",
    "for k in simulation_outcome:\n",
    "    if True in simulation_outcome[k]:\n",
    "        if False in simulation_outcome[k]:\n",
    "            print(k, Counter(simulation_outcome[k]))\n",
    "\n",
    "# So overall there are 8 which have been variably called.\n",
    "# Also lets look at patterns of miss call\n",
    "\n",
    "matching_strings = {}\n",
    "\n",
    "for r in sims:\n",
    "    for k in sims[r]:\n",
    "        matching_strings.setdefault(k, []).append(sims[r][k].matching_string)\n",
    "\n",
    "picture_strings = []\n",
    "m = 0\n",
    "for k in matching_strings:\n",
    "    if len(list(set(matching_strings[k]))) > 1:\n",
    "        m += 1 \n",
    "        picture_strings.append(\"*:*:*:*\")\n",
    "#         print(k, matching_strings[k])\n",
    "    else:\n",
    "        picture_strings.append(matching_strings[k][0])\n",
    "\n",
    "bar_totals = Counter(list(picture_strings))\n",
    "# So overall we have 42 with variable calling (8 occasionally all correct, all other 34 always at least one incorrect)\n",
    "# I think the easiest way to manage this for the picture is to rename them variable\n",
    "# We will therefore replace these strings with **** for working things out\n",
    "\n",
    "ax_labs = ['1:1:1:0', '1:0:1:0', '1:0:1:1', '*:*:*:*', '0:1:1:1', \n",
    "          '0:0:1:1', '0:1:1:0', '0:0:1:0','0:1:0:1', '0:0:0:0']\n",
    "\n",
    "# Note the **** means variably classified across the 10 repeats\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6), dpi=300)\n",
    "ax = plt.subplot2grid((1,1),(0,0), rowspan = 1 , colspan= 1)\n",
    "\n",
    "xs = [k for k in range(len(ax_labs))]\n",
    "ys = [bar_totals[ax_labs[k]] for k in xs]\n",
    "\n",
    "print(xs, ys)\n",
    "\n",
    "ax.bar(xs, ys, color=\"#c51b8a\", width = 0.75)\n",
    "ax.set_xticks(xs)\n",
    "ax.set_xticklabels(ax_labs, size=14,rotation=45 )\n",
    "# Note for the final graph we use those color labels seen in the text\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_ylabel(\"Number of incorrect simulations\", size=16)\n",
    "\n",
    "# This then makes essentially the final image,\n",
    "# Just for anyone keen the numbers I have printed the bar totals dictionary below as well.\n",
    "\n",
    "print(bar_totals)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
